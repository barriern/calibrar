---
title: "Getting started with the calibrar package for parameter estimation"
author: "Ricardo Oliveros-Ramos"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting started with the calibrar package for parameter estimation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
## Introduction

Vignettes are long form documentation commonly included in packages. Because they are part of the distribution of the package, they need to be as compact as possible. The `html_vignette` output type provides a custom style sheet (and tweaks some options) to ensure that the resulting html is as small as possible. The `html_vignette` format:

- Never uses retina figures
- Has a smaller default figure size
- Uses a custom CSS stylesheet instead of the default Twitter Bootstrap style

### Basic usage

```{r, echo=TRUE, results='hide'}
library(calibrar)
calibrate(par=rep(NA, 5), fn=SphereN)
```

```{r, echo=TRUE, results='hide'}
library(calibrar)
calibrate(par=rep(NA, 5), fn=SphereN, replicates=3)
```

```{r, echo=TRUE, results='hide'}
library(calibrar)
calibrate(par=rep(0.5, 5), fn=SphereN, replicates=3, lower=-5, upper=5)
```

```{r, echo=TRUE, results='hide'}
calibrate(par=rep(0.5, 5), fn=SphereN, replicates=c(1,1,4), lower=-5, upper=5, phases=c(1,1,1,2,3))
```

```{r, echo=TRUE, results='hide'}
# this calibration save results on the disk for restart purposes
calibrate(par=rep(0.5, 5), fn=SphereN, replicates=3, lower=-5, upper=5, phases=c(1,1,1,2,3), control=list(restart.file="sphere"))
```

### Running in parallel

```{r, echo=TRUE, results='hide', eval=FALSE}
library(calibrar)
library(doSNOW)
set.seed(880820)
ncores = 6 # number of cores to be used
cl = makeCluster(ncores, type="SOCK")
registerDoSNOW(cl) # register the parallel backend
# this is slower than sequential for very fast models (like this one)
calib = calibrate(par=rep(0.5, 5), fn=SphereN, 
                  replicates=3, 
                  lower=rep(-5, 5), 
                  upper=rep(+5, 5), 
                  phases=c(1,1,1,2,3), 
                  control=list(parallel=TRUE, ncores=ncores))
stopCluster(cl) # close the parallel connections
```

### Optimization algorithms available

### Benchmarking parameter estimation for a linear model

You can write math expressions, e.g. $Y = X\beta + \epsilon$, footnotes^[A footnote here.], and tables, e.g. using `knitr::kable()`.

```{r, echo=TRUE, results='hide'}
N = 7 # number of variables in the linear model
T = 200 # number of observations
noise = FALSE # add gaussian noise to the model
shift = FALSE # add a random shift to the slopes
sd = runif(1) # standard deviation of the gaussian noise
# observed data
x = t(matrix(rnorm(N*T, sd=sd), nrow=N, ncol=T))
# slopes for the linear model (real parameters)
slope = seq_len(N) + shift*sample(c(-10, 10), N, replace=TRUE)
# intercept for the linear model (real parameters)
intercept = pi
# real parameters
real = list(intercept=intercept, slope=slope)
```

```{r, echo=TRUE, results='hide'}
# function to simulate the linear model
linear = function(x, par) {
  stopifnot(length(x)==length(par$slope))
  out = sum(x*par$slope) + par$intercept
  return(out)
}
```

```{r, echo=TRUE, results='hide'}
# simulated data
y = apply(x, 1, linear, par=real) + noise*rnorm(nrow(x), sd=mean(sd))
```

```{r, echo=TRUE, results='hide'}
# objective function (residual squares sum)
obj = function(par, x, y) {
  y_sim = apply(x, 1, linear, par=par)
  out = sum((y_sim - y)^2)
  return(out)
}
```

```{r, echo=TRUE, results='hide'}
lower = relist(rep(-10, N+1), skeleton=start)
upper = relist(rep(+10, N+1), skeleton=start)
# initial guess for optimization
start = list(intercept=0, slope=rep(0, N))
```

```{r, echo=TRUE, results='hide'}
cat("Running optimization algorithms\n")
cat("\t", date(), "\n")

cat("Running linear model\n")
mod = lm(y ~ x)

cat("Running calibrar AHR-ES (unconstrained)\n")
es  = calibrate(par=start, fn=obj, x=x, y=y)

cat("Running calibrar AHR-ES (constrained)\n")
es2 = calibrate(par=start, fn=obj, x=x, y=y, 
                           lower=lower, upper=upper)

cat("Running optim CG\n")
cg  = calibrate(par=start, fn=obj, x=x, y=y, method="CG")

cat("Running optim SANN\n")
sann = calibrate(par=start, fn=obj, x=x, y=y, method="SANN")

cat("Running optimx Nelder-Mead\n")
nm = calibrate(par=start, fn=obj, x=x, y=y, method="Nelder-Mead")

cat("Running optimx BFGS\n")
bfgs = calibrate(par=start, fn=obj, x=x, y=y, method="BFGS")

cat("Running cmaes CMA-ES\n")
cma = calibrate(par=start, fn=obj, x=x, y=y, 
                                   lower=lower, upper=upper, method="cmaes")
```

```{r, echo=TRUE, results='hide'}
final = rbind(real=unlist(real),
              lm=coef(mod),
              'BFGS'        = unlist(bfgs$par),
              'CG'          = unlist(cg$par),
              'AHR-ES'      = unlist(es$par),
              'AHR-ES (constrained)' = unlist(es2$par),
              'SANN'        = unlist(sann$par),
              'CMA-ES'      = unlist(cma$par),
              'Nelder-Mead' = unlist(nm$par))
```

```{r, echo=FALSE, results='asis'}
knitr::kable(final)
```

## Worked examples

### Fitting an EDO system: the Lotka-Volterra Predator-Prey model

### Fitting an EDO system: the SIR epidemiological model

### Fitting an autoregressive Poisson model

### Fitting an stochastic model: an IBM Lotka-Volterra model


```{r, echo=TRUE, results='hide'}

```

```{r, echo=TRUE, results='hide'}

```

```{r, echo=TRUE, results='hide'}

```

```{r, echo=TRUE, results='hide'}

```

```{r, echo=TRUE, results='hide'}

```

## Figures

The figure sizes have been customised so that you can easily put two images side-by-side. 

```{r, fig.show='hold'}
plot(1:10)
plot(10:1)
```

You can enable figure captions by `fig_caption: yes` in YAML:

    output:
      rmarkdown::html_vignette:
        fig_caption: yes

Then you can use the chunk option `fig.cap = "Your figure caption."` in **knitr**.

Also a quote using `>`:

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))
